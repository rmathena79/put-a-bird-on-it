{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e852b022-7e0f-478f-a941-11d983f43c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uniqu\\AppData\\Local\\Temp\\ipykernel_9108\\3735582818.py:53: DtypeWarning: Columns (14,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw_df = pd.read_csv(SOURCE, sep='\\t')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting values for column COMMON_NAME\n",
      "Found 405 unique values\n",
      "Building new dataframe\n",
      "Building replacement maps\n",
      "Replacing all literals with IDs\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# This sample data is provided by eBird with no restrictions:\n",
    "#SOURCE = \"sampledata/ebd_US-AL-101_202204_202204_relApr-2022.txt\"\n",
    "\n",
    "# This is the main dataset, which eBird requires permission to access and is too big to redistribute:\n",
    "SOURCE = \"C:\\\\Users\\\\uniqu\\\\Downloads\\\\ebd_US-OR_202308_202408_relAug-2024\\\\ebd_US-OR_202308_202408_relAug-2024.txt\"\n",
    "\n",
    "OUT_DIR = \"output\"\n",
    "\n",
    "# Important column names. Note these are the final forms, after renaming to remove spaces:\n",
    "COL_ID = 'GLOBAL_UNIQUE_IDENTIFIER'\n",
    "COL_TAX_CATEGORY = 'CATEGORY'\n",
    "COL_COMMON_NAME = 'COMMON_NAME'\n",
    "COL_SCI_NAME = 'SCIENTIFIC_NAME'\n",
    "COL_LAT = 'LATITUDE'\n",
    "COL_LONG = 'LONGITUDE'\n",
    "COL_DATE = 'OBSERVATION_DATE'\n",
    "FINAL_CARE_COLUMNS = [COL_ID, COL_COMMON_NAME, COL_SCI_NAME, COL_LAT, COL_LONG, COL_DATE]\n",
    "NORMALIZE_COLUMNS = [COL_COMMON_NAME, COL_SCI_NAME]\n",
    "\n",
    "def normalize_form(df, column_names):\n",
    "    value_dfs = {}\n",
    "    normalized_df = df.copy()\n",
    "\n",
    "    for column_name in column_names:\n",
    "        print(f\"Extracting values for column {column_name}\")\n",
    "        \n",
    "        # Build a table for the extracted values, giving each unique value an ID number\n",
    "        values = df[column_name].unique()\n",
    "        print(f\"Found {len(values)} unique values\")\n",
    "\n",
    "        ids = np.arange(1, len(values)+1)\n",
    "        print(\"Building new dataframe\")\n",
    "        value_df = pd.DataFrame({'id': ids, column_name: values})\n",
    "        value_dfs[column_name] = value_df\n",
    "\n",
    "        # Replace the literal values with their ID in the original dataframe\n",
    "        print(\"Building replacement maps\")\n",
    "        replacements = {}\n",
    "        for i in range(0, len(values)):\n",
    "            value = values[i]\n",
    "            id = ids[i]\n",
    "            replacements[value] = id\n",
    "\n",
    "        print(\"Replacing all literals with IDs\")\n",
    "        normalized_df[column_name] = normalized_df[column_name].replace(replacements)\n",
    "    return normalized_df, value_dfs\n",
    "\n",
    "# Read the data\n",
    "raw_df = pd.read_csv(SOURCE, sep='\\t')\n",
    "\n",
    "# Drop all sightings categories by anything other than species (just for simplification)\n",
    "df = raw_df.loc[raw_df[COL_TAX_CATEGORY] == 'species']\n",
    "\n",
    "# Change a few column names to avoid spaces in names\n",
    "df = df.rename(columns={COL_ID.replace('_', ' '): COL_ID})\n",
    "df = df.rename(columns={COL_COMMON_NAME.replace('_', ' '): COL_COMMON_NAME})\n",
    "df = df.rename(columns={COL_SCI_NAME.replace('_', ' '): COL_SCI_NAME})\n",
    "df = df.rename(columns={COL_DATE.replace('_', ' '): COL_DATE})\n",
    "\n",
    "# Remove extraneous columns\n",
    "df = df.loc[:, FINAL_CARE_COLUMNS ]\n",
    "\n",
    "# Get the normalized dataframes\n",
    "(ndf, vdfs) = normalize_form(df, NORMALIZE_COLUMNS)\n",
    "\n",
    "# Save all the dataframes as CSV\n",
    "if not os.path.exists(OUT_DIR):\n",
    "    os.makedirs(OUT_DIR)\n",
    "\n",
    "out_path = os.path.join(OUT_DIR, 'normalized.csv')\n",
    "print(f\"Saving main data: {out_path}\")\n",
    "ndf.to_csv(out_path, index=False)\n",
    "for c in NORMALIZE_COLUMNS:\n",
    "    out_path = os.path.join(OUT_DIR, f'{c}.csv')\n",
    "    print(f\"Saving {c} data: {out_path}\")\n",
    "    vdfs[c].to_csv(out_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
